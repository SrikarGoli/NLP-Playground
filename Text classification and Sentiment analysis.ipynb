{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPwcBm/tCoo2nrnENiTyX+F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## **Name:**  Goli Srikar\n","## **RegNo:** 22BCE9946\n","## **Slot No:** L43-L44"],"metadata":{"id":"FI5_iozT_IPC"}},{"cell_type":"markdown","source":["## Week 5"],"metadata":{"id":"tgMfQus7_SC4"}},{"cell_type":"markdown","source":["## Text classification application using GRU"],"metadata":{"id":"Yc62PPAs1AAP"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.datasets import reuters\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, GRU, Dense\n","from sklearn.model_selection import train_test_split\n","from collections import defaultdict\n"],"metadata":{"id":"Iqt3ytxV1Ad7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Reuters dataset\n","num_words = 10000  #top 10,000 words\n","(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=num_words)\n","\n","max_len = 200\n","x_train = pad_sequences(x_train, maxlen=max_len, padding='post', truncating='post')\n","x_test = pad_sequences(x_test, maxlen=max_len, padding='post', truncating='post')\n","\n","# Split training data into training and validation\n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n","\n","#label names\n","def get_reuters_labels():\n","    labels = [\"Cocoa\", \"Grain\", \"Vegetable Oil\", \"Livestock\", \"Cotton\", \"Iron Steel\", \"CPI\", \"Money FX\",\n","              \"Energy\", \"Ship\", \"Sugar\", \"Coffee\", \"Gold\", \"Tin\", \"Strategic Metals\", \"Grain\", \"Retail\",\n","              \"NAT-GAS\", \"Alum\", \"OPEC\", \"Palm Oil\", \"RUBBER\", \"COPPER\", \"COTTON\", \"Wool\", \"TEA\",\n","              \"STRATEGIC METALS\", \"PET-CHEM\", \"COCOA\", \"LIVESTOCK\", \"CORN\", \"WHEAT\", \"SUGAR\", \"COFFEE\",\n","              \"OILSEED\", \"COAL\", \"ORANGE\", \"HEATING\", \"RICE\", \"NICKEL\", \"SILVER\", \"PLATINUM\", \"CPI\",\n","              \"MONEY-FX\", \"INTEREST\", \"TRADE\"]\n","    return defaultdict(lambda: \"Unknown\", {i: label for i, label in enumerate(labels)})\n","\n","label_names = get_reuters_labels()\n","\n","# sample data point\n","def decode_review(encoded_review):\n","    word_index = reuters.get_word_index()\n","    reverse_word_index = {value: key for key, value in word_index.items()}\n","    return ' '.join([reverse_word_index.get(i - 3, '?') for i in encoded_review])\n","\n","print(\"Sample Data Point:\")\n","print(decode_review(x_train[0]))\n","print(f\"Label: {label_names[y_train[0]]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nRa4JpN92iUu","executionInfo":{"status":"ok","timestamp":1742463376974,"user_tz":-330,"elapsed":738,"user":{"displayName":"GOLI SRIKAR 22BCE9946","userId":"08045425248612178511"}},"outputId":"ea6bae97-8fca-44bc-a59d-02b9a37127c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample Data Point:\n","? u s exporters will have the opportunity to sell an additional 300 000 tonnes of u s durum wheat to algeria under the export enhancement program eep the u s agriculture department said the department said the sales will be subsidized with commodities from the commodity credit corporation ccc inventory and the subsidy will enable u s exports to compete at commercial prices in the algerian market algeria has already purchased 300 000 tonnes of u s durum wheat under a previous export enhancement initiative announced november 10 1986 it said details of the latest initiative including an invitation for offers from exporters will be issued in the near future the department said reuter 3 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n","Label: Grain\n"]}]},{"cell_type":"code","source":["# GRU model\n","model = Sequential([\n","    Embedding(input_dim=num_words, output_dim=128, input_length=max_len),\n","    GRU(64, return_sequences=False),\n","    Dense(46, activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_val, y_val))\n","\n","# Evaluate on test data\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print(f'Test Accuracy: {accuracy * 100:.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YDXbxH_b3sbg","executionInfo":{"status":"ok","timestamp":1742463790110,"user_tz":-330,"elapsed":401608,"user":{"displayName":"GOLI SRIKAR 22BCE9946","userId":"08045425248612178511"}},"outputId":"e3d28a2f-dfaa-4a2d-add5-4bb413bf6a2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 302ms/step - accuracy: 0.3199 - loss: 2.9347 - val_accuracy: 0.3606 - val_loss: 2.3540\n","Epoch 2/10\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 305ms/step - accuracy: 0.3678 - loss: 2.3537 - val_accuracy: 0.5281 - val_loss: 1.9524\n","Epoch 3/10\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 301ms/step - accuracy: 0.5352 - loss: 1.8692 - val_accuracy: 0.5860 - val_loss: 1.6683\n","Epoch 4/10\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 295ms/step - accuracy: 0.5966 - loss: 1.5938 - val_accuracy: 0.6038 - val_loss: 1.6005\n","Epoch 5/10\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 307ms/step - accuracy: 0.6372 - loss: 1.4463 - val_accuracy: 0.6071 - val_loss: 1.5879\n","Epoch 6/10\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 324ms/step - accuracy: 0.6712 - loss: 1.3194 - val_accuracy: 0.6422 - val_loss: 1.4743\n","Epoch 7/10\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 336ms/step - accuracy: 0.7261 - loss: 1.1300 - val_accuracy: 0.6667 - val_loss: 1.4090\n","Epoch 8/10\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 308ms/step - accuracy: 0.7647 - loss: 0.9783 - val_accuracy: 0.6923 - val_loss: 1.3259\n","Epoch 9/10\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 319ms/step - accuracy: 0.7996 - loss: 0.8325 - val_accuracy: 0.6945 - val_loss: 1.3161\n","Epoch 10/10\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 314ms/step - accuracy: 0.8189 - loss: 0.7462 - val_accuracy: 0.7023 - val_loss: 1.2946\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6945 - loss: 1.3333\n","Test Accuracy: 68.34%\n"]}]},{"cell_type":"code","source":["# Function to predict category for a custom sentence\n","def predict_category(sentence):\n","    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=num_words)\n","    word_index = reuters.get_word_index()\n","    words = sentence.lower().split()\n","    encoded_sentence = [word_index.get(word, 2) + 3 for word in words]\n","    padded_sentence = pad_sequences([encoded_sentence], maxlen=max_len, padding='post', truncating='post')\n","    prediction = model.predict(padded_sentence)\n","    predicted_label = prediction.argmax()\n","    print(f\"Sentence: {sentence}\")\n","    print(f\"Predicted Category: {label_names[predicted_label]}\")\n","\n","predict_category(\"Stock market is crashing due to economic slowdown.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ynAo9yx2scw","executionInfo":{"status":"ok","timestamp":1742463805249,"user_tz":-330,"elapsed":426,"user":{"displayName":"GOLI SRIKAR 22BCE9946","userId":"08045425248612178511"}},"outputId":"a6dc4729-82d4-4468-8335-aee6c9f350e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step\n","Sentence: Stock market is crashing due to economic slowdown.\n","Predicted Category: Livestock\n"]}]},{"cell_type":"markdown","source":["## Sentiment analyzer using LSTM."],"metadata":{"id":"wpbnRZa3tiZw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fsU5lG5FqzlU"},"outputs":[],"source":["from tensorflow.keras.datasets import imdb\n","from tensorflow.keras.layers import LSTM"]},{"cell_type":"code","source":["#IMDb movie dataset\n","num_words = 10000\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)\n","print(x_train[0])\n","print(y_train[0])\n","\n","max_len = 200\n","x_train = pad_sequences(x_train, maxlen=max_len, padding='post', truncating='post')\n","x_test = pad_sequences(x_test, maxlen=max_len, padding='post', truncating='post')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zcz0FZL_v-3U","executionInfo":{"status":"ok","timestamp":1742461266509,"user_tz":-330,"elapsed":6070,"user":{"displayName":"GOLI SRIKAR 22BCE9946","userId":"08045425248612178511"}},"outputId":"68852537-6fa4-44b9-c963-dcd6bebff893"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n","1\n"]}]},{"cell_type":"code","source":["\n","# Split training data into training and validation\n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n","\n","# Build the LSTM model\n","model = Sequential([\n","    Embedding(input_dim=num_words, output_dim=128, input_length=max_len),\n","    LSTM(64, return_sequences=False),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_val, y_val))\n","\n","# Evaluate on test data\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print(f'Test Accuracy: {accuracy * 100:.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XlBJPLd4xfGM","executionInfo":{"status":"ok","timestamp":1742461943715,"user_tz":-330,"elapsed":650633,"user":{"displayName":"GOLI SRIKAR 22BCE9946","userId":"08045425248612178511"}},"outputId":"856da0e9-dca3-455c-f754-988aeb28cb29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 301ms/step - accuracy: 0.5133 - loss: 0.6919 - val_accuracy: 0.5946 - val_loss: 0.6794\n","Epoch 2/5\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 300ms/step - accuracy: 0.6122 - loss: 0.6616 - val_accuracy: 0.5796 - val_loss: 0.6890\n","Epoch 3/5\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 312ms/step - accuracy: 0.6029 - loss: 0.6460 - val_accuracy: 0.7152 - val_loss: 0.5810\n","Epoch 4/5\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 315ms/step - accuracy: 0.8525 - loss: 0.3512 - val_accuracy: 0.8538 - val_loss: 0.3409\n","Epoch 5/5\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 300ms/step - accuracy: 0.9244 - loss: 0.2101 - val_accuracy: 0.8482 - val_loss: 0.3654\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 38ms/step - accuracy: 0.8408 - loss: 0.3858\n","Test Accuracy: 84.03%\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","# IMDb word index\n","word_index = imdb.get_word_index()\n","reverse_word_index = {value: key for key, value in word_index.items()}\n","\n","# Function to preprocess and predict sentiment for custom sentence\n","def predict_sentiment(sentence):\n","    tokenizer = Tokenizer(num_words=num_words)\n","    words = sentence.lower().split()\n","    encoded_sentence = [word_index.get(word, 2) + 3 for word in words]\n","    padded_sentence = pad_sequences([encoded_sentence], maxlen=max_len, padding='post', truncating='post')\n","\n","    prediction = model.predict(padded_sentence)[0][0]\n","    sentiment = \"Positive\" if prediction > 0.5 else \"Negative\"\n","\n","    print(f\"Sentence: {sentence}\")\n","    print(f\"Sentiment: {sentiment} (Confidence: {prediction:.4f})\")\n","\n","\n","predict_sentiment(\"This movie was fantastic and full of thrilling moments!\")\n","predict_sentiment(\"I hated this movie. It was boring and had no plot.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UNP1VEakyPXo","executionInfo":{"status":"ok","timestamp":1742461952036,"user_tz":-330,"elapsed":2287,"user":{"displayName":"GOLI SRIKAR 22BCE9946","userId":"08045425248612178511"}},"outputId":"ab5454b1-bdc0-44f7-9e8c-69c9b54fea2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n","\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step\n","Sentence: This movie was fantastic and full of thrilling moments!\n","Sentiment: Positive (Confidence: 0.9808)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","Sentence: I hated this movie. It was boring and had no plot.\n","Sentiment: Negative (Confidence: 0.1057)\n"]}]}]}